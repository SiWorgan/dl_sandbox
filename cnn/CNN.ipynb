{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "TO DO:\n",
    "- Different boat validation set\n",
    "- Bring in listed external datasets\n",
    "- Move to inception net\n",
    "- Normalise the data\n",
    "- Look at misclassifications for further ideas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import vgg16\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from vgg16 import Vgg16\n",
    "from inceptionV3 import IncepV3\n",
    "from glob import glob\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = Vgg16()\n",
    "model = IncepV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = 'data/'\n",
    "path = 'data/sample_fish/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sub_path in os.listdir(path+'/train/'):\n",
    "    g = glob(path+'train/'+sub_path+'/*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(int(len(g)*0.2)):\n",
    "        os.rename(shuf[i], path+'valid/' + sub_path + '/' + shuf[i].split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bs=64\n",
    "noe=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 images belonging to 8 classes.\n",
      "Found 11 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = model.get_batches(path+'train', batch_size=bs)\n",
    "valid_batches = model.get_batches(path+'valid', batch_size=bs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonworgan/anaconda/lib/python3.5/site-packages/Keras-1.2.0-py3.5.egg/keras/applications/inception_v3.py:291: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image dimension ordering convention (`image_dim_ordering=\"th\"`). For best performance, set `image_dim_ordering=\"tf\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "model.create(batches.nb_class)\n",
    "model.finetune(batches, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "11/11 [==============================] - 26s - loss: 2.3271 - acc: 0.0909 - val_loss: 2.4919 - val_acc: 0.0909\n",
      "Epoch 2/6\n",
      "11/11 [==============================] - 23s - loss: 1.0027 - acc: 0.9091 - val_loss: 2.1798 - val_acc: 0.0909\n",
      "Epoch 3/6\n",
      "11/11 [==============================] - 24s - loss: 0.1922 - acc: 1.0000 - val_loss: 2.0379 - val_acc: 0.1818\n",
      "Epoch 4/6\n",
      "11/11 [==============================] - 24s - loss: 0.1070 - acc: 1.0000 - val_loss: 1.8309 - val_acc: 0.3636\n",
      "Epoch 5/6\n",
      "11/11 [==============================] - 23s - loss: 0.0566 - acc: 1.0000 - val_loss: 1.7863 - val_acc: 0.3636\n",
      "Epoch 6/6\n",
      "11/11 [==============================] - 24s - loss: 0.0067 - acc: 1.0000 - val_loss: 1.2605 - val_acc: 0.6364\n"
     ]
    }
   ],
   "source": [
    "model.fit(batches, valid_batches, nb_epoch=noe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.model.save_weights('incep_finetune1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now optimise the other dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in model.model.layers[172:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "model.compile(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "11/11 [==============================] - 32s - loss: 0.0030 - acc: 1.0000 - val_loss: 1.6980 - val_acc: 0.4545\n",
      "Epoch 2/6\n",
      "11/11 [==============================] - 27s - loss: 0.0012 - acc: 1.0000 - val_loss: 1.1305 - val_acc: 0.6364\n",
      "Epoch 3/6\n",
      "11/11 [==============================] - 27s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.8908 - val_acc: 0.7273\n",
      "Epoch 4/6\n",
      "11/11 [==============================] - 27s - loss: 0.0013 - acc: 1.0000 - val_loss: 1.2335 - val_acc: 0.5455\n",
      "Epoch 5/6\n",
      "11/11 [==============================] - 26s - loss: 2.8353e-04 - acc: 1.0000 - val_loss: 1.4275 - val_acc: 0.5455\n",
      "Epoch 6/6\n",
      "11/11 [==============================] - 24s - loss: 4.3111e-04 - acc: 1.0000 - val_loss: 0.8226 - val_acc: 0.6364\n"
     ]
    }
   ],
   "source": [
    "model.fit(batches, valid_batches, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.model.save_weights('finetune2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batches, preds = model.test(path+'test_stg1', batch_size = bs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = batches.filenames\n",
    "\n",
    "with open(\"sample_sub.csv\", \"w\") as f:\n",
    "    f.write(\"image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\\n\")\n",
    "    for pred,fn in zip(preds, filenames):\n",
    "        pred = \",\".join(map(lambda x: str(x), pred))\n",
    "        f.write(fn+\",\"+pred+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.model.load_weights('finetune1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batches.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
